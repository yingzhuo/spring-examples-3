# ----------------------------------------------------------------------------------------------------------------------
# 核心配置
# ----------------------------------------------------------------------------------------------------------------------
spring:
  config:
    activate:
      on-profile:
        - debug
debug: true
---

# ----------------------------------------------------------------------------------------------------------------------
# 核心配置
# ----------------------------------------------------------------------------------------------------------------------
spring:
  application:
    name: "examples-kafka"
  aop:
    auto: true
  main:
    web-application-type: servlet
    banner-mode: off
    allow-bean-definition-overriding: true
    lazy-initialization: false
    log-startup-info: true
    cloud-platform: none
    register-shutdown-hook: true
  jackson:
    locale: "zh_CN"
    time-zone: "Asia/Shanghai"
    date-format: "yyyy-MM-dd HH:mm:ss.SSS"
    default-property-inclusion: always
    serialization:
      indent-output: true
      fail-on-self-references: true
      fail-on-empty-beans: false
      write-dates-as-timestamps: false
      write-null-map-values: true
      write-empty-json-arrays: true
      write-single-elem-arrays-unwrapped: false
      write-enums-using-to-string: true
    deserialization:
      fail-on-unknown-properties: false
  lifecycle:
    timeout-per-shutdown-phase: "30s"
  jmx:
    enabled: false
    unique-names: true

  kafka:
    bootstrap-servers: "10.211.55.3:9092"
    producer:
      properties:
        # key序列化器
        "key.serializer": "org.apache.kafka.common.serialization.StringSerializer"
        # value序列化器
        "value.serializer": "org.apache.kafka.common.serialization.StringSerializer"
        # 批量发送满16K发送一批
        "batch.size": 16384
        # 如果数据不满一批到500毫秒以后也发送
        "linger.ms": 500
        # 自定义分区器
        "partitioner.class": "examples.kafka.partition.LoggingPartitioner"
        # 压缩
        "compression.type": "snappy"
        # 缓存大小 32M
        "buffer.memory": "33554432"
        # ack级别
        #  -1: Leader收到，副本也收到
        #  0: 生产者不需要Leader确认，发送完了则认为成功了
        #  all: Leader收到则认为发送成功
        "acks": "all"
        # 重试
        "retries": "3"
        # 开启幂等性特性
        "enable.idempotence": "true"
        # broker端缓存5个数据乱序时不落盘
        "max.in.flight.requests.per.connection": "5"
    consumer:
      properties:
        # 消费者组
        "group.id": "${spring.application.name}"
        # key反序列化器
        "key.deserializer": "org.apache.kafka.common.serialization.StringDeserializer"
        # value反序列化器
        "value.deserializer": "org.apache.kafka.common.serialization.StringDeserializer"
        # 自动或手动ack
        "enable.auto.commit": false
    admin:
      fail-fast: true
